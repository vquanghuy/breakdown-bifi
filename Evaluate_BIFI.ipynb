{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8af7951-c602-4e39-b863-8d2bf7de7be6",
   "metadata": {},
   "source": [
    "# Additional setup\n",
    "\n",
    "If we're running on the remote environment such as Vast.ai, additional setup is required including\n",
    "\n",
    "- Download and install necessary libraries\n",
    "- Download and extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df01683-a0ff-446e-9387-205d5e516462",
   "metadata": {},
   "source": [
    "## System specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7f358a-3685-431f-b18d-536e22f3dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\n",
      "NAME=\"Ubuntu\"\n",
      "VERSION_ID=\"22.04\"\n",
      "VERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\n",
      "VERSION_CODENAME=jammy\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "UBUNTU_CODENAME=jammy\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2eb6211-2954-48bd-aeea-b95d3d1b7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 14 04:59:51 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.100                Driver Version: 550.100        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:61:00.0 Off |                  N/A |\n",
      "|  0%   54C    P8             23W /  350W |       1MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fe7a-4d3a-401a-9a6e-fee119403ce3",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa87592-13a3-445e-aa79-d94d348fdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 386 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Fetched 175 kB in 1s (268 kB/s)[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 22469 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394d494d-43fe-4df9-a887-c56b58f74432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting editdistance\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.16.0)\n",
      "Collecting cython (from fairseq)\n",
      "  Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting omegaconf<2.1 (from fairseq)\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting regex (from fairseq)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu>=1.4.12 (from fairseq)\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Collecting bitarray (from fairseq)\n",
      "  Downloading bitarray-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.26.4)\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.11.0)\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq) (1.3.0)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10414487 sha256=66d69ad7d1d47663207e8f00b171a119ac7fe24f9f8177c82a5c1275b661dbd0\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=00c300fb1bbd3af2072cbd339d68287220e41d4d69923ab2eea1767049996cfb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "Successfully built fairseq antlr4-python3-runtime\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, tabulate, regex, portalocker, omegaconf, lxml, editdistance, cython, colorama, sacrebleu, hydra-core, gdown, fairseq\n",
      "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.3 colorama-0.4.6 cython-3.0.11 editdistance-0.8.1 fairseq-0.12.2 gdown-5.2.0 hydra-core-1.0.7 lxml-5.3.0 omegaconf-2.0.6 portalocker-2.10.1 regex-2024.9.11 sacrebleu-2.4.3 tabulate-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gdown fairseq editdistance tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e150f-dff9-4e81-91d9-940927213b14",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166886e-5f72-46fa-94e3-e4fa4d1c7048",
   "metadata": {},
   "source": [
    "### Check working directory existance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b6659a2-9483-42eb-8e98-5bf92d18108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Working directory /workspace/breakdown-bifi\n",
      "Directory 'data-eval' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('[!] Working directory', os.getcwd())\n",
    "\n",
    "data_eval_dir = 'data-eval'\n",
    "\n",
    "# Check if the eval directory exists\n",
    "if not os.path.exists(data_eval_dir):\n",
    "  os.makedirs(data_eval_dir)\n",
    "  print(f\"-> Directory '{data_eval_dir}' created successfully!\")\n",
    "else:\n",
    "  print(f\"Directory '{data_eval_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d35d1-835a-4e2b-9e77-f57467abe2a8",
   "metadata": {},
   "source": [
    "### Download token vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70478348-a038-47ae-9683-dd81d7f6f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-JLsekCMygk1DSkbA9kQHLJeEPBUWyJM\n",
      "To: /workspace/breakdown-bifi/data-eval/token_vocab.txt\n",
      "100%|██████████| 130k/130k [00:00<00:00, 2.31MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data-eval/token_vocab.txt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vocab_url = \"https://drive.google.com/uc?id=1-JLsekCMygk1DSkbA9kQHLJeEPBUWyJM\"\n",
    "token_vocab_output_path = os.path.join(data_eval_dir, \"token_vocab.txt\")\n",
    "\n",
    "gdown.download(token_vocab_url, token_vocab_output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4066864d-997e-4c86-a73f-c5d2119cb213",
   "metadata": {},
   "source": [
    "### Download and unzip orig_bad_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f2a385a-37b9-4720-96d7-dbe5510a98e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12DIzvqty2ZwcH4KSaZ6I3rhU34EN4Bd-\n",
      "To: /workspace/breakdown-bifi/data-eval/orig_bad_code.zip\n",
      "100%|██████████| 14.5M/14.5M [00:01<00:00, 11.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-eval/orig_bad_code.zip\n",
      "   creating: data-eval/orig_bad_code/\n",
      "  inflating: data-eval/__MACOSX/._orig_bad_code  \n",
      "  inflating: data-eval/orig_bad_code/orig.4.bad  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.4.bad  \n",
      "  inflating: data-eval/orig_bad_code/orig.0.bad  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.0.bad  \n",
      "  inflating: data-eval/orig_bad_code/orig.1.bad  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.1.bad  \n",
      "  inflating: data-eval/orig_bad_code/orig.3.bad  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.3.bad  \n",
      "  inflating: data-eval/orig_bad_code/orig.2.bad  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.2.bad  \n",
      "  inflating: data-eval/orig_bad_code/orig.2.id  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.2.id  \n",
      "  inflating: data-eval/orig_bad_code/orig.3.id  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.3.id  \n",
      "  inflating: data-eval/orig_bad_code/orig.0.id  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.0.id  \n",
      "  inflating: data-eval/orig_bad_code/orig.4.id  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.4.id  \n",
      "  inflating: data-eval/orig_bad_code/orig.1.id  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.1.id  \n",
      "  inflating: data-eval/orig_bad_code/orig.bad.json  \n",
      "  inflating: data-eval/__MACOSX/orig_bad_code/._orig.bad.json  \n"
     ]
    }
   ],
   "source": [
    "orig_bad_code_url = \"https://drive.google.com/uc?id=12DIzvqty2ZwcH4KSaZ6I3rhU34EN4Bd-\"\n",
    "orig_bad_code_output_path = os.path.join(data_eval_dir, \"orig_bad_code.zip\")\n",
    "\n",
    "gdown.download(id=\"12DIzvqty2ZwcH4KSaZ6I3rhU34EN4Bd-\", output=orig_bad_code_output_path, quiet=False)\n",
    "!unzip {orig_bad_code_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152882d-08c3-4d95-ae3e-821a750404bd",
   "metadata": {},
   "source": [
    "### Download and unzip round 0 data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3fc2cb-5013-46b2-89cd-5de4ba225cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_0_url = \"https://drive.google.com/uc?id=13vgvSLaeffUsPR0NSLfiYTzHUK3q4L-y\"\n",
    "round_0_output_path = os.path.join(data_eval_dir, \"round_0.zip\")\n",
    "\n",
    "gdown.download(round_0_url, round_0_output_path, quiet=False)\n",
    "!unzip {round_0_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527f748-7a77-4e39-a9dd-5f915759013f",
   "metadata": {},
   "source": [
    "### Download and unzip round 1 - BIFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204f613-5221-470a-ae13-57e8e5f9a4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7fb256f4087037",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b31f957775deb8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:54:00.497834Z",
     "start_time": "2024-10-13T04:53:55.826035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Torch 2.3.1\n",
      "fairseq 0.12.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# Check PyTorch version\n",
    "import torch\n",
    "print('Torch', torch.__version__)\n",
    "\n",
    "import fairseq\n",
    "print('fairseq', fairseq.__version__)\n",
    "\n",
    "import sys\n",
    "import json, os, re\n",
    "\n",
    "sys.path.insert(0, 'utils')  # Replace with the actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51aa14d9039b4b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:33.843483Z",
     "start_time": "2024-10-13T04:55:33.723099Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data-eval'\n",
    "os.environ[\"DATA_DIR\"] = DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:35.590866Z",
     "start_time": "2024-10-13T04:55:35.448218Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from utils.code_error_checker import check_paren_error, check_ast_error\n",
    "from utils.code_utils import preprocess_unk, code_toks_to_code_string, get_diff_metric, tokenize_python_code\n",
    "from utils.fairseq_utils import parse_fairseq_preds, fairseq_preprocess, fairseq_generate, fairseq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be6e9b57c2d95ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:38.538528Z",
     "start_time": "2024-10-13T04:55:38.421381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Torch', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94124861557d77e2",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9e5a353b763b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_pred_obj(pred_obj):\n",
    "    # Deal with UNK\n",
    "    _, unk_dict = preprocess_unk(pred_obj['code_toks_raw'])\n",
    "    anonymize_dict = pred_obj['anonymize_dict']\n",
    "    if anonymize_dict is None:\n",
    "        anonymize_dict = {}\n",
    "    anonymize_dict['<unk>'] = unk_dict\n",
    "    anonymize_dict['<STRING>'] = []\n",
    "    anonymize_dict['<COMMENT>'] = []\n",
    "    #\n",
    "    src = pred_obj['src'] #this is tok_format i.e. ' '.join(code_toks)\n",
    "    src_code  = code_toks_to_code_string(src, anonymize_dict) #this is string_format\n",
    "    ret_obj = {'progid': pred_obj['progid'],\n",
    "               'orig_err_obj': pred_obj['orig_err_obj'],\n",
    "               'anonymize_dict': pred_obj['anonymize_dict']\n",
    "               }\n",
    "    ret_obj['src']  = {'tok_format': src, 'string_format': src_code}\n",
    "    #Get string_format from predicted code toks\n",
    "    ret_obj['pred'] = []\n",
    "    for pred in pred_obj['pred']:\n",
    "        pred_code = code_toks_to_code_string(pred, anonymize_dict) #this is string_format\n",
    "        orig_err_obj = pred_obj['orig_err_obj']\n",
    "        if orig_err_obj['msg'] == 'unbalanced (){}[]':\n",
    "            #NOTE: `pred` is tok_format i.e. ' '.join(code_toks)\n",
    "            res = check_paren_error(pred.split())\n",
    "        else:\n",
    "            res = check_ast_error(pred_code)\n",
    "        diff_metric = get_diff_metric(src, pred)\n",
    "        ret_obj['pred'].append({'tok_format': pred,\n",
    "                                'string_format': pred_code,\n",
    "                                'err_obj': res,\n",
    "                                'diff_metric': diff_metric})\n",
    "    return ret_obj\n",
    "\n",
    "def eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=80):\n",
    "    pred_dir   = f'{pred_dir_prefix}{split}'\n",
    "    pred_path = Path(f'{pred_dir}/{pred_fname}')\n",
    "    preds = parse_fairseq_preds(str(pred_path))\n",
    "    #load progids\n",
    "    data_dir = DATA_DIR\n",
    "    progids = [l.strip() for l in open(f'{data_dir}/orig_bad_code/orig.{split}.id')]\n",
    "    assert len(preds) == len(progids)\n",
    "    #load original err_obj\n",
    "    bads = json.load(open(f'{data_dir}/orig_bad_code/orig.bad.json'))\n",
    "    for j in range(len(preds)):\n",
    "        progid = progids[j]\n",
    "        preds[j]['progid'] = progid\n",
    "        preds[j]['orig_err_obj'] = bads[progid]['err_obj']\n",
    "        code_toks_raw = bads[progid]['code_toks_joined'].split()\n",
    "        anonymize_dict = bads[progid]['anonymize_dict']\n",
    "        if 'window_span' in bads[progid]:\n",
    "            ws = bads[progid]['window_span']\n",
    "            code_toks_raw = code_toks_raw[ws[0]:ws[1]]\n",
    "            anonymize_dict = None\n",
    "        preds[j]['code_toks_raw'] = code_toks_raw\n",
    "        preds[j]['anonymize_dict'] = anonymize_dict\n",
    "    #\n",
    "    print ('len(preds)', len(preds))\n",
    "    # with Pool(n_workers) as p:\n",
    "    #     res = list(tqdm(p.imap(eval_one_pred_obj, preds), total=len(preds)))\n",
    "    res = list(tqdm(map(eval_one_pred_obj, preds)))  # or list(tqdm([eval_one_pred_obj(pred) for pred in preds]))\n",
    "\n",
    "    '''\n",
    "      res: list of {'progid': , 'orig_err_obj': , 'anonymize_dict': ,\n",
    "                    'src': {'tok_format': , 'string_format': },\n",
    "                    'pred': {'tok_format':, 'string_format':, 'err_obj': }\n",
    "                    }\n",
    "    '''\n",
    "    with open(f'{pred_path.parent}/{pred_path.stem}.evaluated.json', 'w') as f:\n",
    "        json.dump(res, f, indent=2)\n",
    "\n",
    "def get_test_result(pred_dir_prefix, pred_fname):\n",
    "    #\n",
    "    def collate_eval():\n",
    "        success  = []; denom = 0\n",
    "        success_by_group = defaultdict(list); denom_by_group = defaultdict(int)\n",
    "        agg_obj = {}\n",
    "        for split in {3,4}: #heldout test set\n",
    "            print ('split', split)\n",
    "            pred_dir   = Path(f'{pred_dir_prefix}{split}')\n",
    "            pred_path  = pred_dir/pred_fname\n",
    "            pred_eval_path = f'{pred_path.parent}/{pred_path.stem}.evaluated.json'\n",
    "            eval_objs = json.load(open(pred_eval_path))\n",
    "            for eval_obj in eval_objs:\n",
    "                progid = eval_obj['progid']\n",
    "                orig_err_type = eval_obj['orig_err_obj']['msg']\n",
    "                if 'indent' in orig_err_type:\n",
    "                    orig_err_type = 'indentation error'\n",
    "                denom += 1\n",
    "                denom_by_group[orig_err_type] += 1\n",
    "                for k, pred_obj in enumerate(eval_obj['pred']):\n",
    "                    pred_err_obj = pred_obj['err_obj']\n",
    "                    diff_metric  = pred_obj['diff_metric']\n",
    "                    if (pred_err_obj == 0) and (0 < diff_metric <= 4):\n",
    "                        name = '{:02d}-{}-{:03d}'.format(split, progid, k)\n",
    "                        success.append(name)\n",
    "                        success_by_group[orig_err_type].append(name)\n",
    "        return success, denom, success_by_group, denom_by_group\n",
    "    #\n",
    "    def print_stats(name_list, _denom):\n",
    "        top1 = set()\n",
    "        for name in name_list:\n",
    "            split, progid, k = name.split('-')\n",
    "            if int(split) in {3,4}: #test set\n",
    "                if int(k)==0:\n",
    "                    top1.add(f'{split}-{progid}')\n",
    "        acc = len(top1)/float(_denom)*100\n",
    "        print ('   acc: {} ({:.1f}%) | denom {}'.format(len(top1), acc, _denom))\n",
    "        return acc\n",
    "    #\n",
    "    success, denom, success_by_group, denom_by_group = collate_eval()\n",
    "    acc_dict = {}\n",
    "    print ('Total'); acc = print_stats(success, denom); acc_dict['total'] = acc\n",
    "    print ('-'*50)\n",
    "    for err_type in success_by_group:\n",
    "        print (f'{err_type.capitalize()}')\n",
    "        acc = print_stats(success_by_group[err_type], denom_by_group[err_type])\n",
    "        acc_dict[err_type] = acc\n",
    "    json.dump(acc_dict, open(Path(pred_dir_prefix).parent/'stats.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9e99ab957478",
   "metadata": {},
   "source": [
    "# Evaluate Round 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74991804e3aa5537",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b1ca3dde40534b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T08:45:43.480130Z",
     "start_time": "2024-10-13T08:45:43.358131Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_0'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe0979ede6f5c1",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ad08ffd0f67cbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:39:48.223511Z",
     "start_time": "2024-10-13T09:07:07.066145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model-fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 05:07:55 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 05:07:57 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model-fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 05:07:57 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 05:07:57 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 05:07:57 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model-fixer/checkpoint.pt\n",
      "2024-10-14 05:08:23 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad\n",
      "2024-10-14 05:08:23 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0 test bad-good 7528 examples\n",
      "2024-10-14 05:12:47 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 05:12:47 | INFO | fairseq_cli.generate | Translated 7,528 sentences (555,536 tokens) in 108.0s (69.68 sentences/s, 5142.33 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model-fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 05:12:55 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 05:12:57 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model-fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 05:12:57 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 05:12:57 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 05:12:57 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model-fixer/checkpoint.pt\n",
      "2024-10-14 05:13:21 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad\n",
      "2024-10-14 05:13:21 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1 test bad-good 7528 examples\n",
      "2024-10-14 05:17:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 05:17:39 | INFO | fairseq_cli.generate | Translated 7,528 sentences (549,686 tokens) in 103.7s (72.58 sentences/s, 5299.98 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model-fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 05:17:46 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 05:17:48 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model-fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 05:17:48 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 05:17:48 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 05:17:48 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model-fixer/checkpoint.pt\n",
      "2024-10-14 05:18:13 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad\n",
      "2024-10-14 05:18:13 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2 test bad-good 7528 examples\n",
      "2024-10-14 05:22:31 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 05:22:31 | INFO | fairseq_cli.generate | Translated 7,528 sentences (549,503 tokens) in 104.6s (71.95 sentences/s, 5251.69 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model-fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 05:22:38 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 05:22:40 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model-fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 05:22:41 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 05:22:41 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 05:22:41 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model-fixer/checkpoint.pt\n",
      "2024-10-14 05:23:06 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad\n",
      "2024-10-14 05:23:06 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3 test bad-good 7528 examples\n",
      "2024-10-14 05:27:23 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 05:27:23 | INFO | fairseq_cli.generate | Translated 7,528 sentences (547,976 tokens) in 102.9s (73.17 sentences/s, 5326.30 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model-fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 05:27:30 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 05:27:33 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model-fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 05:27:33 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 05:27:33 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 05:27:33 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model-fixer/checkpoint.pt\n",
      "2024-10-14 05:27:56 | INFO | fairseq.data.data_utils | loaded 7,527 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad\n",
      "2024-10-14 05:27:56 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4 test bad-good 7527 examples\n",
      "2024-10-14 05:32:14 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 05:32:14 | INFO | fairseq_cli.generate | Translated 7,527 sentences (550,192 tokens) in 105.1s (71.60 sentences/s, 5233.75 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=10, nbest=10, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba926b3bf0d64c4",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df232f153a660eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:40:51.066394Z",
     "start_time": "2024-10-13T09:39:48.228500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:11, 645.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:11, 673.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:11, 679.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:11, 672.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:11, 668.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 9341 (62.0%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3508 (87.7%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 3350 (70.5%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 2483 (39.4%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf013710b649ca",
   "metadata": {},
   "source": [
    "# Evaluate FixerOnly - Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed774af5ec21dc70",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3b6105f58df067d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T10:17:58.270244Z",
     "start_time": "2024-10-13T10:17:58.146169Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_fixer_only'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b24e1a0371de5",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "292853fa4c6d2532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:19:11.391151Z",
     "start_time": "2024-10-13T10:55:21.226578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=5, nbest=5, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af197ea7980c5e1a",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de61a86d86d97917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:21:32.156620Z",
     "start_time": "2024-10-13T11:20:54.682200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1384.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1444.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1402.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1427.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:05, 1356.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13067 (86.8%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3730 (93.3%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4321 (91.0%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5016 (79.5%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d43d087adb8a75",
   "metadata": {},
   "source": [
    "# Evaluate BIFI - Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25916316f6924f94",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4beb395b06e94dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:47:51.407011Z",
     "start_time": "2024-10-13T11:47:51.284613Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_bifi'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5df77dd59bbf9",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cf82526812fc23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:00.026022Z",
     "start_time": "2024-10-13T12:53:29.876302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=1, nbest=1, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f15f42496ee318",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "524410fe1f344f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:12.039310Z",
     "start_time": "2024-10-13T13:40:00.037061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5761.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5734.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5672.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5573.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:01, 6041.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13171 (87.5%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3757 (93.9%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4335 (91.3%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5079 (80.5%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7219cb3212b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
