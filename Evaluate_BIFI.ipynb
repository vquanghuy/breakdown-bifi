{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8af7951-c602-4e39-b863-8d2bf7de7be6",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "\n",
    "If we're running on the remote environment such as Vast.ai, additional setup is required including\n",
    "\n",
    "- Download and install necessary libraries\n",
    "- Download and extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df01683-a0ff-446e-9387-205d5e516462",
   "metadata": {},
   "source": [
    "## System specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7f358a-3685-431f-b18d-536e22f3dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\n",
      "NAME=\"Ubuntu\"\n",
      "VERSION_ID=\"22.04\"\n",
      "VERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\n",
      "VERSION_CODENAME=jammy\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "UBUNTU_CODENAME=jammy\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2eb6211-2954-48bd-aeea-b95d3d1b7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 14 13:44:51 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 50%   40C    P8               8W / 320W |      1MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fe7a-4d3a-401a-9a6e-fee119403ce3",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa87592-13a3-445e-aa79-d94d348fdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-26ubuntu3.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394d494d-43fe-4df9-a887-c56b58f74432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\n",
      "Requirement already satisfied: fairseq in /opt/conda/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: editdistance in /opt/conda/lib/python3.10/site-packages (0.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.2)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.16.0)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq) (3.0.11)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.0.6)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq) (2024.9.11)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.4.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.9.3)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.26.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.11.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (2.10.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (5.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq) (1.3.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gdown fairseq editdistance tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e150f-dff9-4e81-91d9-940927213b14",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166886e-5f72-46fa-94e3-e4fa4d1c7048",
   "metadata": {},
   "source": [
    "### Check working directory existance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6659a2-9483-42eb-8e98-5bf92d18108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Working directory /workspace/jupyter-bifi-adaptation\n",
      "Directory 'data-eval' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "print('[!] Working directory', os.getcwd())\n",
    "\n",
    "data_eval_dir = 'data-eval'\n",
    "\n",
    "# Check if the eval directory exists\n",
    "if not os.path.exists(data_eval_dir):\n",
    "  os.makedirs(data_eval_dir)\n",
    "  print(f\"-> Directory '{data_eval_dir}' created successfully!\")\n",
    "else:\n",
    "  print(f\"Directory '{data_eval_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d35d1-835a-4e2b-9e77-f57467abe2a8",
   "metadata": {},
   "source": [
    "### Download token vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70478348-a038-47ae-9683-dd81d7f6f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-JLsekCMygk1DSkbA9kQHLJeEPBUWyJM\n",
      "To: /workspace/jupyter-bifi-adaptation/data-eval/token_vocab.txt\n",
      "100%|██████████| 130k/130k [00:00<00:00, 2.25MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data-eval/token_vocab.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vocab_output_path = os.path.join(data_eval_dir, \"token_vocab.txt\")\n",
    "\n",
    "gdown.download(id=\"1-JLsekCMygk1DSkbA9kQHLJeEPBUWyJM\", output=token_vocab_output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4066864d-997e-4c86-a73f-c5d2119cb213",
   "metadata": {},
   "source": [
    "### Download and unzip orig_bad_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2a385a-37b9-4720-96d7-dbe5510a98e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12DIzvqty2ZwcH4KSaZ6I3rhU34EN4Bd-\n",
      "To: /workspace/jupyter-bifi-adaptation/data-eval/orig_bad_code.zip\n",
      "100%|██████████| 14.5M/14.5M [00:01<00:00, 10.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-eval/orig_bad_code.zip\n"
     ]
    }
   ],
   "source": [
    "orig_bad_code_output_path = os.path.join(data_eval_dir, \"orig_bad_code.zip\")\n",
    "\n",
    "gdown.download(id=\"12DIzvqty2ZwcH4KSaZ6I3rhU34EN4Bd-\", output=orig_bad_code_output_path, quiet=False)\n",
    "!unzip -f {orig_bad_code_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152882d-08c3-4d95-ae3e-821a750404bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download and unzip round 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c3fc2cb-5013-46b2-89cd-5de4ba225cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-eval/round_0.zip\n",
      "   creating: data-eval/round_0/model_fixer/\n",
      "  inflating: data-eval/round_0/model_fixer/checkpoint.pt  \n",
      "  inflating: data-eval/round_0/model_fixer/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/stats.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/desktop.ini  \n",
      "  inflating: data-eval/round_0/desktop.ini  \n"
     ]
    }
   ],
   "source": [
    "round_0_output_path = os.path.join(data_eval_dir, \"round_0.zip\")\n",
    "\n",
    "gdown.download(id=\"13vgvSLaeffUsPR0NSLfiYTzHUK3q4L-y\", output=round_0_output_path, quiet=False)\n",
    "!unzip -o {round_0_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23665c-84b2-4716-9383-ee5d50093c8f",
   "metadata": {},
   "source": [
    "### Download and unzip round 1 - Fixer Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32069e98-9040-460d-8462-bac4a2cf42b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-eval/round_0.zip\n",
      "   creating: data-eval/round_0/model_fixer/\n",
      "  inflating: data-eval/round_0/model_fixer/checkpoint.pt  \n",
      "  inflating: data-eval/round_0/model_fixer/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/stats.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/dict.bad.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/dict.good.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/model-fixer.pred.evaluated.json  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/model-fixer.pred.txt  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/preprocess.log  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad.bin  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad.idx  \n",
      "  inflating: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/desktop.ini  \n",
      "  inflating: data-eval/round_0/orig_bad/desktop.ini  \n",
      "  inflating: data-eval/round_0/desktop.ini  \n"
     ]
    }
   ],
   "source": [
    "round_0_output_path = os.path.join(data_eval_dir, \"round_0.zip\")\n",
    "\n",
    "gdown.download(id=\"13vgvSLaeffUsPR0NSLfiYTzHUK3q4L-y\", output=round_0_output_path, quiet=False)\n",
    "!unzip -o {round_0_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527f748-7a77-4e39-a9dd-5f915759013f",
   "metadata": {},
   "source": [
    "### Download and unzip round 1 - BIFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b204f613-5221-470a-ae13-57e8e5f9a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=12TuHRvsMIaOt5t6QhsvVbWi29L6kfvay\n",
      "From (redirected): https://drive.google.com/uc?id=12TuHRvsMIaOt5t6QhsvVbWi29L6kfvay&confirm=t&uuid=28bbdddb-12a5-4cd1-b594-b452d966a6aa\n",
      "To: /workspace/jupyter-bifi-adaptation/data-eval/round_1_bifi.zip\n",
      "100%|██████████| 149M/149M [00:01<00:00, 89.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-eval/round_1_bifi.zip\n"
     ]
    }
   ],
   "source": [
    "round_1_bifi_output_path = os.path.join(data_eval_dir, \"round_1_bifi.zip\")\n",
    "\n",
    "gdown.download(id=\"12TuHRvsMIaOt5t6QhsvVbWi29L6kfvay\", output=round_1_bifi_output_path, quiet=False)\n",
    "!unzip -o {round_1_bifi_output_path} -d {data_eval_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7fb256f4087037",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31f957775deb8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:54:00.497834Z",
     "start_time": "2024-10-13T04:53:55.826035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 13:46:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq 0.12.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# Check PyTorch version\n",
    "import torch\n",
    "print('Torch', torch.__version__)\n",
    "\n",
    "import fairseq\n",
    "print('fairseq', fairseq.__version__)\n",
    "\n",
    "import sys\n",
    "import json, os, re\n",
    "\n",
    "sys.path.insert(0, 'utils')  # Replace with the actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51aa14d9039b4b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:33.843483Z",
     "start_time": "2024-10-13T04:55:33.723099Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data-eval'\n",
    "os.environ[\"DATA_DIR\"] = DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:35.590866Z",
     "start_time": "2024-10-13T04:55:35.448218Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from utils.code_error_checker import check_paren_error, check_ast_error\n",
    "from utils.code_utils import preprocess_unk, code_toks_to_code_string, get_diff_metric, tokenize_python_code\n",
    "from utils.fairseq_utils import parse_fairseq_preds, fairseq_preprocess, fairseq_generate, fairseq_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94124861557d77e2",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e5a353b763b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_pred_obj(pred_obj):\n",
    "    # Deal with UNK\n",
    "    _, unk_dict = preprocess_unk(pred_obj['code_toks_raw'])\n",
    "    anonymize_dict = pred_obj['anonymize_dict']\n",
    "    if anonymize_dict is None:\n",
    "        anonymize_dict = {}\n",
    "    anonymize_dict['<unk>'] = unk_dict\n",
    "    anonymize_dict['<STRING>'] = []\n",
    "    anonymize_dict['<COMMENT>'] = []\n",
    "    #\n",
    "    src = pred_obj['src'] #this is tok_format i.e. ' '.join(code_toks)\n",
    "    src_code  = code_toks_to_code_string(src, anonymize_dict) #this is string_format\n",
    "    ret_obj = {'progid': pred_obj['progid'],\n",
    "               'orig_err_obj': pred_obj['orig_err_obj'],\n",
    "               'anonymize_dict': pred_obj['anonymize_dict']\n",
    "               }\n",
    "    ret_obj['src']  = {'tok_format': src, 'string_format': src_code}\n",
    "    #Get string_format from predicted code toks\n",
    "    ret_obj['pred'] = []\n",
    "    for pred in pred_obj['pred']:\n",
    "        pred_code = code_toks_to_code_string(pred, anonymize_dict) #this is string_format\n",
    "        orig_err_obj = pred_obj['orig_err_obj']\n",
    "        if orig_err_obj['msg'] == 'unbalanced (){}[]':\n",
    "            #NOTE: `pred` is tok_format i.e. ' '.join(code_toks)\n",
    "            res = check_paren_error(pred.split())\n",
    "        else:\n",
    "            res = check_ast_error(pred_code)\n",
    "        diff_metric = get_diff_metric(src, pred)\n",
    "        ret_obj['pred'].append({'tok_format': pred,\n",
    "                                'string_format': pred_code,\n",
    "                                'err_obj': res,\n",
    "                                'diff_metric': diff_metric})\n",
    "    return ret_obj\n",
    "\n",
    "def eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=80):\n",
    "    pred_dir   = f'{pred_dir_prefix}{split}'\n",
    "    pred_path = Path(f'{pred_dir}/{pred_fname}')\n",
    "    preds = parse_fairseq_preds(str(pred_path))\n",
    "    #load progids\n",
    "    data_dir = DATA_DIR\n",
    "    progids = [l.strip() for l in open(f'{data_dir}/orig_bad_code/orig.{split}.id')]\n",
    "    assert len(preds) == len(progids)\n",
    "    #load original err_obj\n",
    "    bads = json.load(open(f'{data_dir}/orig_bad_code/orig.bad.json'))\n",
    "    for j in range(len(preds)):\n",
    "        progid = progids[j]\n",
    "        preds[j]['progid'] = progid\n",
    "        preds[j]['orig_err_obj'] = bads[progid]['err_obj']\n",
    "        code_toks_raw = bads[progid]['code_toks_joined'].split()\n",
    "        anonymize_dict = bads[progid]['anonymize_dict']\n",
    "        if 'window_span' in bads[progid]:\n",
    "            ws = bads[progid]['window_span']\n",
    "            code_toks_raw = code_toks_raw[ws[0]:ws[1]]\n",
    "            anonymize_dict = None\n",
    "        preds[j]['code_toks_raw'] = code_toks_raw\n",
    "        preds[j]['anonymize_dict'] = anonymize_dict\n",
    "    #\n",
    "    print ('len(preds)', len(preds))\n",
    "    # with Pool(n_workers) as p:\n",
    "    #     res = list(tqdm(p.imap(eval_one_pred_obj, preds), total=len(preds)))\n",
    "    res = list(tqdm(map(eval_one_pred_obj, preds)))  # or list(tqdm([eval_one_pred_obj(pred) for pred in preds]))\n",
    "\n",
    "    '''\n",
    "      res: list of {'progid': , 'orig_err_obj': , 'anonymize_dict': ,\n",
    "                    'src': {'tok_format': , 'string_format': },\n",
    "                    'pred': {'tok_format':, 'string_format':, 'err_obj': }\n",
    "                    }\n",
    "    '''\n",
    "    with open(f'{pred_path.parent}/{pred_path.stem}.evaluated.json', 'w') as f:\n",
    "        json.dump(res, f, indent=2)\n",
    "\n",
    "def get_test_result(pred_dir_prefix, pred_fname):\n",
    "    #\n",
    "    def collate_eval():\n",
    "        success  = []; denom = 0\n",
    "        success_by_group = defaultdict(list); denom_by_group = defaultdict(int)\n",
    "        agg_obj = {}\n",
    "        for split in {3,4}: #heldout test set\n",
    "            print ('split', split)\n",
    "            pred_dir   = Path(f'{pred_dir_prefix}{split}')\n",
    "            pred_path  = pred_dir/pred_fname\n",
    "            pred_eval_path = f'{pred_path.parent}/{pred_path.stem}.evaluated.json'\n",
    "            eval_objs = json.load(open(pred_eval_path))\n",
    "            for eval_obj in eval_objs:\n",
    "                progid = eval_obj['progid']\n",
    "                orig_err_type = eval_obj['orig_err_obj']['msg']\n",
    "                if 'indent' in orig_err_type:\n",
    "                    orig_err_type = 'indentation error'\n",
    "                denom += 1\n",
    "                denom_by_group[orig_err_type] += 1\n",
    "                for k, pred_obj in enumerate(eval_obj['pred']):\n",
    "                    pred_err_obj = pred_obj['err_obj']\n",
    "                    diff_metric  = pred_obj['diff_metric']\n",
    "                    if (pred_err_obj == 0) and (0 < diff_metric <= 4):\n",
    "                        name = '{:02d}-{}-{:03d}'.format(split, progid, k)\n",
    "                        success.append(name)\n",
    "                        success_by_group[orig_err_type].append(name)\n",
    "        return success, denom, success_by_group, denom_by_group\n",
    "    #\n",
    "    def print_stats(name_list, _denom):\n",
    "        top1 = set()\n",
    "        for name in name_list:\n",
    "            split, progid, k = name.split('-')\n",
    "            if int(split) in {3,4}: #test set\n",
    "                if int(k)==0:\n",
    "                    top1.add(f'{split}-{progid}')\n",
    "        acc = len(top1)/float(_denom)*100\n",
    "        print ('   acc: {} ({:.1f}%) | denom {}'.format(len(top1), acc, _denom))\n",
    "        return acc\n",
    "    #\n",
    "    success, denom, success_by_group, denom_by_group = collate_eval()\n",
    "    acc_dict = {}\n",
    "    print ('Total'); acc = print_stats(success, denom); acc_dict['total'] = acc\n",
    "    print ('-'*50)\n",
    "    for err_type in success_by_group:\n",
    "        print (f'{err_type.capitalize()}')\n",
    "        acc = print_stats(success_by_group[err_type], denom_by_group[err_type])\n",
    "        acc_dict[err_type] = acc\n",
    "    json.dump(acc_dict, open(Path(pred_dir_prefix).parent/'stats.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0a097b-9744-4775-8660-c1270a127055",
   "metadata": {},
   "source": [
    "# Param config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e59868-cd08-4853-9f5f-ad749f986b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM = 10\n",
    "NBEST = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9e99ab957478",
   "metadata": {},
   "source": [
    "# Evaluate Round 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74991804e3aa5537",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b1ca3dde40534b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T08:45:43.480130Z",
     "start_time": "2024-10-13T08:45:43.358131Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_0'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model_fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe0979ede6f5c1",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad08ffd0f67cbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:39:48.223511Z",
     "start_time": "2024-10-13T09:07:07.066145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 13:55:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 13:55:21 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 13:55:21 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 13:55:21 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 13:55:21 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model_fixer/checkpoint.pt\n",
      "2024-10-14 13:55:24 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad\n",
      "2024-10-14 13:55:24 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.0 test bad-good 7528 examples\n",
      "2024-10-14 13:59:19 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 13:59:19 | INFO | fairseq_cli.generate | Translated 7,528 sentences (555,536 tokens) in 51.1s (147.46 sentences/s, 10881.77 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 13:59:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 13:59:28 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 13:59:28 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 13:59:28 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 13:59:28 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model_fixer/checkpoint.pt\n",
      "2024-10-14 13:59:31 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad\n",
      "2024-10-14 13:59:31 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.1 test bad-good 7528 examples\n",
      "2024-10-14 14:03:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:03:24 | INFO | fairseq_cli.generate | Translated 7,528 sentences (549,686 tokens) in 50.4s (149.46 sentences/s, 10913.31 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:03:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:03:33 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:03:33 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:03:33 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:03:33 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:03:35 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad\n",
      "2024-10-14 14:03:35 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.2 test bad-good 7528 examples\n",
      "2024-10-14 14:07:26 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:07:26 | INFO | fairseq_cli.generate | Translated 7,528 sentences (549,503 tokens) in 50.6s (148.89 sentences/s, 10868.02 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:07:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:07:35 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:07:35 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:07:35 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:07:35 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:07:38 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad\n",
      "2024-10-14 14:07:38 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.3 test bad-good 7528 examples\n",
      "2024-10-14 14:11:26 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:11:26 | INFO | fairseq_cli.generate | Translated 7,528 sentences (547,976 tokens) in 50.1s (150.21 sentences/s, 10934.35 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_0/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:11:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:11:35 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_0/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:11:35 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:11:35 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:11:35 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_0/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:11:37 | INFO | fairseq.data.data_utils | loaded 7,527 examples from: data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad\n",
      "2024-10-14 14:11:37 | INFO | fairseq.tasks.translation | data-eval/round_0/orig_bad/fairseq_preprocess__orig_bad.4 test bad-good 7527 examples\n",
      "2024-10-14 14:15:28 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:15:28 | INFO | fairseq_cli.generate | Translated 7,527 sentences (550,192 tokens) in 51.3s (146.82 sentences/s, 10731.76 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    if os.path.exists(pred_path):\n",
    "        os.remove(pred_path)\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=BEAM, nbest=NBEST, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba926b3bf0d64c4",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df232f153a660eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:40:51.066394Z",
     "start_time": "2024-10-13T09:39:48.228500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:10, 718.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:10, 744.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:10, 746.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:10, 747.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:10, 744.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 9341 (62.0%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3508 (87.7%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 3350 (70.5%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 2483 (39.4%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf013710b649ca",
   "metadata": {},
   "source": [
    "# Evaluate FixerOnly - Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed774af5ec21dc70",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3b6105f58df067d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T10:17:58.270244Z",
     "start_time": "2024-10-13T10:17:58.146169Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_fixer_only'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b24e1a0371de5",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "292853fa4c6d2532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:19:11.391151Z",
     "start_time": "2024-10-13T10:55:21.226578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "\n",
    "    if os.path.exists(pred_path):\n",
    "        os.remove(pred_path)\n",
    "    \n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=BEAM, nbest=NBEST, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af197ea7980c5e1a",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de61a86d86d97917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:21:32.156620Z",
     "start_time": "2024-10-13T11:20:54.682200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1384.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1444.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1402.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1427.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:05, 1356.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13067 (86.8%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3730 (93.3%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4321 (91.0%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5016 (79.5%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d43d087adb8a75",
   "metadata": {},
   "source": [
    "# Evaluate BIFI - Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25916316f6924f94",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4beb395b06e94dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:47:51.407011Z",
     "start_time": "2024-10-13T11:47:51.284613Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_bifi'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model_fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5df77dd59bbf9",
   "metadata": {},
   "source": [
    "## Perform fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cf82526812fc23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:00.026022Z",
     "start_time": "2024-10-13T12:53:29.876302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_1_bifi/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:23:12 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:23:14 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_1_bifi/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.0', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:23:14 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:23:14 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:23:14 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_1_bifi/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:23:17 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.0/test.bad-good.bad\n",
      "2024-10-14 14:23:17 | INFO | fairseq.tasks.translation | data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.0 test bad-good 7528 examples\n",
      "2024-10-14 14:27:16 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:27:16 | INFO | fairseq_cli.generate | Translated 7,528 sentences (557,271 tokens) in 52.2s (144.32 sentences/s, 10683.15 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_1_bifi/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:27:23 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:27:25 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_1_bifi/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.1', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:27:25 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:27:25 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:27:25 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_1_bifi/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:27:27 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.1/test.bad-good.bad\n",
      "2024-10-14 14:27:27 | INFO | fairseq.tasks.translation | data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.1 test bad-good 7528 examples\n",
      "2024-10-14 14:31:23 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:31:23 | INFO | fairseq_cli.generate | Translated 7,528 sentences (550,989 tokens) in 51.6s (145.89 sentences/s, 10677.78 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_1_bifi/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:31:30 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:31:32 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_1_bifi/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.2', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:31:32 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:31:32 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:31:32 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_1_bifi/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:31:35 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.2/test.bad-good.bad\n",
      "2024-10-14 14:31:35 | INFO | fairseq.tasks.translation | data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.2 test bad-good 7528 examples\n",
      "2024-10-14 14:35:23 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:35:23 | INFO | fairseq_cli.generate | Translated 7,528 sentences (550,933 tokens) in 50.5s (149.01 sentences/s, 10905.00 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_1_bifi/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:35:30 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:35:32 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_1_bifi/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.3', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:35:32 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:35:32 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:35:32 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_1_bifi/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:35:35 | INFO | fairseq.data.data_utils | loaded 7,528 examples from: data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.3/test.bad-good.bad\n",
      "2024-10-14 14:35:35 | INFO | fairseq.tasks.translation | data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.3 test bad-good 7528 examples\n",
      "2024-10-14 14:39:30 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:39:30 | INFO | fairseq_cli.generate | Translated 7,528 sentences (549,530 tokens) in 51.0s (147.66 sentences/s, 10779.13 tokens/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data-eval/round_1_bifi/model_fixer/checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:39:37 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2024-10-14 14:39:39 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'data-eval/round_1_bifi/model_fixer/checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 7000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 7000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'nbest': 10, 'max_len_a': 1.0, 'max_len_b': 50, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.4', 'source_lang': 'bad', 'target_lang': 'good', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2024-10-14 14:39:39 | INFO | fairseq.tasks.translation | [bad] dictionary: 10000 types\n",
      "2024-10-14 14:39:39 | INFO | fairseq.tasks.translation | [good] dictionary: 10000 types\n",
      "2024-10-14 14:39:39 | INFO | fairseq_cli.generate | loading model(s) from data-eval/round_1_bifi/model_fixer/checkpoint.pt\n",
      "2024-10-14 14:39:42 | INFO | fairseq.data.data_utils | loaded 7,527 examples from: data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.4/test.bad-good.bad\n",
      "2024-10-14 14:39:42 | INFO | fairseq.tasks.translation | data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad.4 test bad-good 7527 examples\n",
      "2024-10-14 14:43:42 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-10-14 14:43:42 | INFO | fairseq_cli.generate | Translated 7,527 sentences (551,729 tokens) in 51.9s (144.92 sentences/s, 10622.59 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    \n",
    "    if os.path.exists(pred_path):\n",
    "        os.remove(pred_path)\n",
    "    \n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=BEAM, nbest=NBEST, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f15f42496ee318",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "524410fe1f344f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:12.039310Z",
     "start_time": "2024-10-13T13:40:00.037061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-eval/round_1_bifi/orig_bad/fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:08, 878.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:08, 887.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:08, 860.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:08, 887.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:08, 885.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13244 (88.0%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3765 (94.1%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4348 (91.6%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5131 (81.4%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
