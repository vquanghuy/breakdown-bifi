{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "fd7fb256f4087037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:54:00.497834Z",
     "start_time": "2024-10-13T04:53:55.826035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# Check PyTorch version\n",
    "import torch\n",
    "print('Torch', torch.__version__)\n",
    "\n",
    "import fairseq\n",
    "print('fairseq', fairseq.__version__)\n",
    "\n",
    "import sys\n",
    "import json, os, re\n",
    "\n",
    "sys.path.insert(0, 'utils')  # Replace with the actual path"
   ],
   "id": "b31f957775deb8d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.3.1\n",
      "fairseq 0.12.2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:33.843483Z",
     "start_time": "2024-10-13T04:55:33.723099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = 'data'\n",
    "os.environ[\"DATA_DIR\"] = DATA_DIR"
   ],
   "id": "51aa14d9039b4b2b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:35.590866Z",
     "start_time": "2024-10-13T04:55:35.448218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, OrderedDict\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from utils.code_error_checker import check_paren_error, check_ast_error\n",
    "from utils.code_utils import preprocess_unk, code_toks_to_code_string, get_diff_metric, tokenize_python_code\n",
    "from utils.fairseq_utils import parse_fairseq_preds, fairseq_preprocess, fairseq_generate, fairseq_train\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T04:55:38.538528Z",
     "start_time": "2024-10-13T04:55:38.421381Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "be6e9b57c2d95ccd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Common functions",
   "id": "94124861557d77e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def eval_one_pred_obj(pred_obj):\n",
    "    # Deal with UNK\n",
    "    _, unk_dict = preprocess_unk(pred_obj['code_toks_raw'])\n",
    "    anonymize_dict = pred_obj['anonymize_dict']\n",
    "    if anonymize_dict is None:\n",
    "        anonymize_dict = {}\n",
    "    anonymize_dict['<unk>'] = unk_dict\n",
    "    anonymize_dict['<STRING>'] = []\n",
    "    anonymize_dict['<COMMENT>'] = []\n",
    "    #\n",
    "    src = pred_obj['src'] #this is tok_format i.e. ' '.join(code_toks)\n",
    "    src_code  = code_toks_to_code_string(src, anonymize_dict) #this is string_format\n",
    "    ret_obj = {'progid': pred_obj['progid'],\n",
    "               'orig_err_obj': pred_obj['orig_err_obj'],\n",
    "               'anonymize_dict': pred_obj['anonymize_dict']\n",
    "               }\n",
    "    ret_obj['src']  = {'tok_format': src, 'string_format': src_code}\n",
    "    #Get string_format from predicted code toks\n",
    "    ret_obj['pred'] = []\n",
    "    for pred in pred_obj['pred']:\n",
    "        pred_code = code_toks_to_code_string(pred, anonymize_dict) #this is string_format\n",
    "        orig_err_obj = pred_obj['orig_err_obj']\n",
    "        if orig_err_obj['msg'] == 'unbalanced (){}[]':\n",
    "            #NOTE: `pred` is tok_format i.e. ' '.join(code_toks)\n",
    "            res = check_paren_error(pred.split())\n",
    "        else:\n",
    "            res = check_ast_error(pred_code)\n",
    "        diff_metric = get_diff_metric(src, pred)\n",
    "        ret_obj['pred'].append({'tok_format': pred,\n",
    "                                'string_format': pred_code,\n",
    "                                'err_obj': res,\n",
    "                                'diff_metric': diff_metric})\n",
    "    return ret_obj\n",
    "\n",
    "def eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=80):\n",
    "    pred_dir   = f'{pred_dir_prefix}{split}'\n",
    "    pred_path = Path(f'{pred_dir}/{pred_fname}')\n",
    "    preds = parse_fairseq_preds(str(pred_path))\n",
    "    #load progids\n",
    "    data_dir = DATA_DIR\n",
    "    progids = [l.strip() for l in open(f'{data_dir}/orig_bad_code/orig.{split}.id')]\n",
    "    assert len(preds) == len(progids)\n",
    "    #load original err_obj\n",
    "    bads = json.load(open(f'{data_dir}/orig_bad_code/orig.bad.json'))\n",
    "    for j in range(len(preds)):\n",
    "        progid = progids[j]\n",
    "        preds[j]['progid'] = progid\n",
    "        preds[j]['orig_err_obj'] = bads[progid]['err_obj']\n",
    "        code_toks_raw = bads[progid]['code_toks_joined'].split()\n",
    "        anonymize_dict = bads[progid]['anonymize_dict']\n",
    "        if 'window_span' in bads[progid]:\n",
    "            ws = bads[progid]['window_span']\n",
    "            code_toks_raw = code_toks_raw[ws[0]:ws[1]]\n",
    "            anonymize_dict = None\n",
    "        preds[j]['code_toks_raw'] = code_toks_raw\n",
    "        preds[j]['anonymize_dict'] = anonymize_dict\n",
    "    #\n",
    "    print ('len(preds)', len(preds))\n",
    "    # with Pool(n_workers) as p:\n",
    "    #     res = list(tqdm(p.imap(eval_one_pred_obj, preds), total=len(preds)))\n",
    "    res = list(tqdm(map(eval_one_pred_obj, preds)))  # or list(tqdm([eval_one_pred_obj(pred) for pred in preds]))\n",
    "\n",
    "    '''\n",
    "      res: list of {'progid': , 'orig_err_obj': , 'anonymize_dict': ,\n",
    "                    'src': {'tok_format': , 'string_format': },\n",
    "                    'pred': {'tok_format':, 'string_format':, 'err_obj': }\n",
    "                    }\n",
    "    '''\n",
    "    with open(f'{pred_path.parent}/{pred_path.stem}.evaluated.json', 'w') as f:\n",
    "        json.dump(res, f, indent=2)\n",
    "\n",
    "def get_test_result(pred_dir_prefix, pred_fname):\n",
    "    #\n",
    "    def collate_eval():\n",
    "        success  = []; denom = 0\n",
    "        success_by_group = defaultdict(list); denom_by_group = defaultdict(int)\n",
    "        agg_obj = {}\n",
    "        for split in {3,4}: #heldout test set\n",
    "            print ('split', split)\n",
    "            pred_dir   = Path(f'{pred_dir_prefix}{split}')\n",
    "            pred_path  = pred_dir/pred_fname\n",
    "            pred_eval_path = f'{pred_path.parent}/{pred_path.stem}.evaluated.json'\n",
    "            eval_objs = json.load(open(pred_eval_path))\n",
    "            for eval_obj in eval_objs:\n",
    "                progid = eval_obj['progid']\n",
    "                orig_err_type = eval_obj['orig_err_obj']['msg']\n",
    "                if 'indent' in orig_err_type:\n",
    "                    orig_err_type = 'indentation error'\n",
    "                denom += 1\n",
    "                denom_by_group[orig_err_type] += 1\n",
    "                for k, pred_obj in enumerate(eval_obj['pred']):\n",
    "                    pred_err_obj = pred_obj['err_obj']\n",
    "                    diff_metric  = pred_obj['diff_metric']\n",
    "                    if (pred_err_obj == 0) and (0 < diff_metric <= 4):\n",
    "                        name = '{:02d}-{}-{:03d}'.format(split, progid, k)\n",
    "                        success.append(name)\n",
    "                        success_by_group[orig_err_type].append(name)\n",
    "        return success, denom, success_by_group, denom_by_group\n",
    "    #\n",
    "    def print_stats(name_list, _denom):\n",
    "        top1 = set()\n",
    "        for name in name_list:\n",
    "            split, progid, k = name.split('-')\n",
    "            if int(split) in {3,4}: #test set\n",
    "                if int(k)==0:\n",
    "                    top1.add(f'{split}-{progid}')\n",
    "        acc = len(top1)/float(_denom)*100\n",
    "        print ('   acc: {} ({:.1f}%) | denom {}'.format(len(top1), acc, _denom))\n",
    "        return acc\n",
    "    #\n",
    "    success, denom, success_by_group, denom_by_group = collate_eval()\n",
    "    acc_dict = {}\n",
    "    print ('Total'); acc = print_stats(success, denom); acc_dict['total'] = acc\n",
    "    print ('-'*50)\n",
    "    for err_type in success_by_group:\n",
    "        print (f'{err_type.capitalize()}')\n",
    "        acc = print_stats(success_by_group[err_type], denom_by_group[err_type])\n",
    "        acc_dict[err_type] = acc\n",
    "    json.dump(acc_dict, open(Path(pred_dir_prefix).parent/'stats.json', 'w'), indent=2)"
   ],
   "id": "d9e5a353b763b359"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Round 0\n",
   "id": "7ae9e99ab957478"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare environment",
   "id": "74991804e3aa5537"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T08:45:43.480130Z",
     "start_time": "2024-10-13T08:45:43.358131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_0'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ],
   "id": "3b1ca3dde40534b0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fix errors",
   "id": "43fe0979ede6f5c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:39:48.223511Z",
     "start_time": "2024-10-13T09:07:07.066145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=10, nbest=10, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ],
   "id": "7ad08ffd0f67cbe9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 10         --beam 10 --max-tokens 7000 \n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the fix",
   "id": "9ba926b3bf0d64c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T09:40:51.066394Z",
     "start_time": "2024-10-13T09:39:48.228500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ],
   "id": "df232f153a660eb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:09, 792.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:09, 807.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:09, 779.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:09, 786.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:09, 788.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13064 (86.8%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3732 (93.3%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4317 (90.9%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5015 (79.5%) | denom 6307\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate FixerOnly - Round 1",
   "id": "3fcf013710b649ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare environment",
   "id": "ed774af5ec21dc70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T10:17:58.270244Z",
     "start_time": "2024-10-13T10:17:58.146169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_fixer_only'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ],
   "id": "e3b6105f58df067d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fix errors on bad dataset",
   "id": "718b24e1a0371de5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:19:11.391151Z",
     "start_time": "2024-10-13T10:55:21.226578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=5, nbest=5, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ],
   "id": "292853fa4c6d2532",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_fixer_only\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 5         --beam 5 --max-tokens 7000 \n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate",
   "id": "af197ea7980c5e1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:21:32.156620Z",
     "start_time": "2024-10-13T11:20:54.682200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ],
   "id": "de61a86d86d97917",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\round_1_fixer_only\\orig_bad\\fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1384.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1444.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1402.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:05, 1427.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:05, 1356.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13067 (86.8%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3730 (93.3%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4321 (91.0%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5016 (79.5%) | denom 6307\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate BIFI - Round 1",
   "id": "89d43d087adb8a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare environment",
   "id": "25916316f6924f94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:47:51.407011Z",
     "start_time": "2024-10-13T11:47:51.284613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "round_dir = data_dir/'round_1_bifi'\n",
    "\n",
    "# Run fixer\n",
    "model_dir  = round_dir/'model-fixer'\n",
    "model_path = model_dir/'checkpoint.pt'\n",
    "destdir_root = round_dir/'orig_bad'\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "# Evaluate\n",
    "pred_dir_root = round_dir/'orig_bad'\n",
    "pred_dir_prefix = str(pred_dir_root/'fairseq_preprocess__orig_bad.')\n",
    "pred_fname  = 'model-fixer.pred.txt'"
   ],
   "id": "d4beb395b06e94dd",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "95300afdc568e23d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fix errors",
   "id": "34e5df77dd59bbf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:00.026022Z",
     "start_time": "2024-10-13T12:53:29.876302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for split in range(n_splits):\n",
    "    destdir    = destdir_root/f'fairseq_preprocess__orig_bad.{split}'\n",
    "    pred_path  = destdir/'model-fixer.pred.txt'\n",
    "    fairseq_generate(str(destdir), str(model_path), str(pred_path),\n",
    "                     src='bad', tgt='good', gen_subset='test',\n",
    "                     beam=1, nbest=1, max_len_a=1, max_len_b=50, max_tokens=7000)"
   ],
   "id": "1cf82526812fc23d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.0         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.1         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.2         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.3         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n",
      "fairseq-generate             data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad.4         --source-lang bad --target-lang good         --gen-subset test         --path data\\round_1_bifi\\model-fixer\\checkpoint.pt         --max-len-a 1         --max-len-b 50         --nbest 1         --beam 1 --max-tokens 7000 \n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate",
   "id": "35f15f42496ee318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:40:12.039310Z",
     "start_time": "2024-10-13T13:40:00.037061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(pred_dir_prefix, pred_fname)\n",
    "for split in range(n_splits):\n",
    "    eval_one_split(pred_dir_prefix, split, pred_fname, n_workers=10)\n",
    "\n",
    "get_test_result(pred_dir_prefix, pred_fname)"
   ],
   "id": "524410fe1f344f66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\round_1_bifi\\orig_bad\\fairseq_preprocess__orig_bad. model-fixer.pred.txt\n",
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5761.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5734.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5672.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7528it [00:01, 5573.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(preds) 7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7527it [00:01, 6041.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "split 4\n",
      "Total\n",
      "   acc: 13171 (87.5%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3757 (93.9%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4335 (91.3%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5079 (80.5%) | denom 6307\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14b7219cb3212b75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
